{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Back Propagation\n",
    "We introduce back propagation in numpy and pytorch respectively. \n",
    "\n",
    "\n",
    "If you have some questions or suggestion about **BackPropagation with Numpy**, contact Jiaxin Zhuang or email(zhuangjx5@mail2.sysu.edu.cn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple expressions and interpretation of the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Simple expressions\n",
    "Lets start simple so that we can develop the notation and conventions for more complex expressions. Consider a simple multiplication function of two numbers $f(x,y)=xy$. It is a matter of simple calculus to derive the partial derivative for either input:\n",
    "\n",
    "\n",
    "\n",
    "$$f(x,y) = x y \\hspace{0.5in} \\rightarrow \\hspace{0.5in} \\frac{\\partial f}{\\partial x} = y \\hspace{0.5in} \\frac{\\partial f}{\\partial y} = x$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:36:07.329239Z",
     "start_time": "2019-03-14T07:36:07.326692Z"
    }
   },
   "outputs": [],
   "source": [
    "# set some inputs\n",
    "x1 = -2; x2 = 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:36:08.204066Z",
     "start_time": "2019-03-14T07:36:08.201981Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform the forward pass\n",
    "f = x1 * x2 # f becomes -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:36:09.313588Z",
     "start_time": "2019-03-14T07:36:09.310779Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform the backward pass (backpropagation) in reverse order:\n",
    "# backprop through f = x * y\n",
    "dfdx1 = x2 # df/dx = y, so gradient on x becomes 5\n",
    "print(\"gradient on x is {:2}\".format(dfdx1))\n",
    "dfdx2 = x1 # df/dy = x, so gradient on y becomes -2\n",
    "print('gradient on y is {:2}'.format(dfdx2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 interpretation of the gradient\n",
    "**Interpretation**:The derivatives indicate the rate of change of a function with respect to that variable surrounding an infinitesimally small region near a particular point:\n",
    "$$\\frac{df(x)}{dx} = \\lim_{h\\ \\to 0} \\frac{f(x + h) - f(x)}{h}$$\n",
    "In other words, the derivative on each variable tells you the sensitivity of the whole expression on its value.As mentioned, the gradient $\\nabla f$ is the vector of partial derivatives, so we have that $\\nabla f = [\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}] = [y, x]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compound expressions with chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Simple examples for chain rule\n",
    "Lets now start to consider more complicated expressions that involve multiple composed functions, such as $f(x,y,z) = (x + y) z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This expression is still simple enough to differentiate directly, but we’ll take a particular approach to it that will be helpful with understanding the intuition behind backpropagation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, note that this expression can be broken down into two expressions: $q=x+y$ and $f=qz$. As seen in the previous section,$f$ is just multiplication of $q$ and $z$, so $\\frac{\\partial f}{\\partial q} = z, \\frac{\\partial f}{\\partial z} = q$,and $q$ is addition of $x$ and $y$ so $\\frac{\\partial q}{\\partial x} = 1, \\frac{\\partial q}{\\partial y} = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we don’t necessarily care about the gradient on the intermediate value $q$ - the value of $\\frac{\\partial f}{\\partial q}$ is not useful. Instead, we are ultimately interested in the gradient of $f$ with respect to its inputs $x$,$y$,$z$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chain rule tells us that the correct way to “chain” these gradient expressions together is through multiplication. For example, $\\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial q} \\frac{\\partial q}{\\partial x}$. In practice this is simply a **multiplication** of the two numbers that hold the two gradients. Lets see this with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:36:22.161277Z",
     "start_time": "2019-03-14T07:36:22.158944Z"
    }
   },
   "outputs": [],
   "source": [
    "# set some inputs\n",
    "x = -2; y = 5; z = -4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:36:24.099206Z",
     "start_time": "2019-03-14T07:36:24.095881Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform the forward pass\n",
    "q = 2*x + y # q becomes 1\n",
    "f = q * z # f becomes -4\n",
    "print(q, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:36:24.600368Z",
     "start_time": "2019-03-14T07:36:24.592185Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform the backward pass (backpropagation) in reverse order:\n",
    "# first backprop through f = q * z = (2*x+y) * z\n",
    "dfdz = q # df/dz = q, so gradient on z becomes 3\n",
    "dfdq = z # df/dq = z, so gradient on q becomes -4\n",
    "# now backprop through q = x + y\n",
    "dfdx = 2.0 * dfdq # dq/dx = 1. And the multiplication here is the chain rule!\n",
    "dfdy = 1.0 * dfdq # dq/dy = 1\n",
    "print('df/dx is {:2}'.format(dfdx))\n",
    "print('df/dy is {:2}'.format(dfdy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Intuitive understanding of backpropagation\n",
    "Notice that backpropagation is a beautifully local process. \n",
    "Every gate in a circuit diagram gets some inputs and can right away compute two things: \n",
    "1. its output value and \n",
    "2. the local gradient of its inputs with respect to its output value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Practice: Writing a simple Feedforward Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Outline\n",
    "We would implement a simple feedforward neural network by using **numpy**. Thus, we need to define network and implement the forward pass as well as the backword propagation.\n",
    "\n",
    "1. Define a simpel feedforward neural netork, with 1 hidden layer. Implement **forward** and **backward**\n",
    "2. Load data from local csv file with **pandas**, which contains some training and testing dots, generated by 3 different gaussian distribution.(different mean and std).\n",
    "3. Define some functions for visualization and training\n",
    "4. Training and predicting every epoch\n",
    "6. plot the distribution of the points' label and the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:42:08.129415Z",
     "start_time": "2019-03-14T07:42:08.125283Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load necessary module for later\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T09:35:07.435711Z",
     "start_time": "2019-03-13T09:35:07.432973Z"
    }
   },
   "source": [
    "### 3.2  Define a Feedforward Neural Netowk,  implement forward and backward\n",
    "A simple Neural Network with 1 hidden layer.\n",
    "\n",
    "```\n",
    "                                   Networks Structure\n",
    "                         \n",
    "                                    Input        Weights            Output\n",
    "Hidden Layer                     [batch_size, 2] x [2,5]   ->   [batch_size, 5]\n",
    "activation function(sigmoid)     [batch_size, 5]           ->   [batch_size, 5]\n",
    "Classification Layer             [batch_size, 5] x [5,3]   ->   [batch_size, 3]\n",
    "activation function(sigmoid)     [batch_size, 3]           ->   [batch_size, 3]\n",
    "```\n",
    "\n",
    "According to training and testing data. Each points is in two-dimension space, and there is three categories. And predictions would be a one-hot vector, like \\[0 0 1\\] , \\[1 0 0\\], \\[0 1 0\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:42:12.631746Z",
     "start_time": "2019-03-14T07:42:12.626875Z"
    }
   },
   "outputs": [],
   "source": [
    "w1_initialization = np.random.randn(2, 5)  \n",
    "w2_initialization = np.random.randn(5, 3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:43:38.931521Z",
     "start_time": "2019-03-14T07:43:38.928028Z"
    }
   },
   "outputs": [],
   "source": [
    "w2_initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:49:35.423228Z",
     "start_time": "2019-03-14T07:49:35.412233Z"
    }
   },
   "outputs": [],
   "source": [
    "class FeedForward_Neural_Network(object):\n",
    "    def __init__(self, learning_rate):\n",
    "        self.input_channel = 2  #  number of input neurons\n",
    "        self.output_channel = 3 #  number of output neurons\n",
    "        self.hidden_channel = 5 # number of hidden neurons\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # weights initialization\n",
    "        # Usually, we use random or uniform initialzation to initialize weight\n",
    "        # For simplicity, here we use same array to initialze \n",
    "#         np.random.randn(self.input_channel, self.hidden_channel) \n",
    "        # (2x5) weight matrix from input to hidden layer\n",
    "        self.weight1 = np.array([[ 2.12444863,  0.25264613,  1.45417876,  0.56923979,  0.45822365],\n",
    "                                 [-0.80933344,  0.86407349,  0.20170137, -1.87529904, -0.56850693]])\n",
    "         \n",
    "        # (5x3) weight matrix from hidden to output layer\n",
    "#         np.random.randn(self.hidden_channel, self.output_channel)  \n",
    "        self.weight2 = np.array([ [-0.06510141,  0.80681666, -0.5778176 ],\n",
    "                               [ 0.57306064, -0.33667496,  0.29700734],\n",
    "                               [-0.37480416,  0.15510474,  0.70485719],\n",
    "                               [ 0.8452178 , -0.65818079,  0.56810558],\n",
    "                               [ 0.51538125, -0.61564998,  0.92611427]])\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"forward propagation through our network\n",
    "        \"\"\"\n",
    "        # dot product of X (input) and first set of 3x2 weights\n",
    "        self.h1 = np.dot(X, self.weight1)  \n",
    "        # activation function\n",
    "        self.z1 = self.sigmoid(self.h1)  \n",
    "        # dot product of hidden layer (z2) and second set of 3x1 weights\n",
    "        self.h2 = np.dot(self.z1, self.weight2) \n",
    "        # final activation function\n",
    "        o = self.sigmoid(self.h2)\n",
    "        return o\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"Backward, compute gradient and update parameters\n",
    "        Inputs:\n",
    "            X: data, [batch_size, 2]\n",
    "            y: label, one-hot vector, [batch_size, 3]\n",
    "            o: predictions, [batch_size, 3]\n",
    "        \"\"\"\n",
    "        # backward propgate through the network\n",
    "        self.o_error = y - o  # error in output\n",
    "         # applying derivative of sigmoid to error  delata L\n",
    "        self.o_delta = self.o_error * self.sigmoid_prime(o) \n",
    "\n",
    "        # z1 error: how much our hidden layer weights contributed to output error\n",
    "        self.z1_error = self.o_delta.dot(self.weight2.T)  \n",
    "        # applying derivative of sigmoid to z1 error\n",
    "        self.z1_delta = self.z1_error * self.sigmoid_prime(self.z1)  \n",
    "\n",
    "        # adjusting first set (input --> hidden) weights\n",
    "        self.weight1 += X.T.dot(self.z1_delta) * self.learning_rate  \n",
    "        # adjusting second set (hidden --> output) weights\n",
    "        self.weight2 += self.z1.T.dot(self.o_delta) * self.learning_rate \n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        \"\"\"activation function\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "\n",
    "    def sigmoid_prime(self, s):\n",
    "        \"\"\"derivative of sigmoid\n",
    "        \"\"\"\n",
    "        return s * (1 - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T09:05:48.483569Z",
     "start_time": "2019-03-13T09:05:48.478180Z"
    }
   },
   "source": [
    "### 3.3 Loading Data From local csv by using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:02.363604Z",
     "start_time": "2019-03-14T07:37:02.361296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Module\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:02.663403Z",
     "start_time": "2019-03-14T07:37:02.639681Z"
    }
   },
   "outputs": [],
   "source": [
    "train_csv_file = './labels/train.csv'\n",
    "test_csv_file = './labels/test.csv'\n",
    "# Load data from csv file, without header\n",
    "train_frame = pd.read_csv(train_csv_file, encoding='utf-8', header=None)\n",
    "test_frame = pd.read_csv(test_csv_file, encoding='utf-8', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:02.870331Z",
     "start_time": "2019-03-14T07:37:02.850035Z"
    }
   },
   "outputs": [],
   "source": [
    "# show data in Dataframe format (defined in pandas)\n",
    "train_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:06.403453Z",
     "start_time": "2019-03-14T07:37:06.391015Z"
    }
   },
   "outputs": [],
   "source": [
    "# obtain data from specific columns\n",
    "\n",
    "# obtain data from first and second columns and convert into narray\n",
    "train_data = train_frame.iloc[:,0:2].values \n",
    "# obtain labels from third columns and convert into narray\n",
    "train_labels = train_frame.iloc[:,2].values \n",
    "# obtain data from first and second columns and convert into narray\n",
    "test_data = test_frame.iloc[:,0:2].values\n",
    "# obtain labels from third columns and convert into narray\n",
    "test_labels = test_frame.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:06.863783Z",
     "start_time": "2019-03-14T07:37:06.856376Z"
    }
   },
   "outputs": [],
   "source": [
    "# train & test data shape\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "# train & test labels shape\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T03:12:46.188936Z",
     "start_time": "2019-03-14T03:12:46.186299Z"
    }
   },
   "source": [
    "### 3.4 Define some function for visualization and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:14.384519Z",
     "start_time": "2019-03-14T07:37:14.380680Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot(data, labels, caption):\n",
    "    \"\"\"plot the data distribution, !!YOU CAN READ THIS LATER, if you are interested\n",
    "    \"\"\"\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(set(labels))))\n",
    "    for i in set(labels):\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for index, label in enumerate(labels):\n",
    "            if label == i:\n",
    "                xs.append(data[index][0])\n",
    "                ys.append(data[index][1])\n",
    "        plt.scatter(xs, ys, colors[int(i)])    \n",
    "    plt.title(caption)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:16.229769Z",
     "start_time": "2019-03-14T07:37:16.119350Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(train_data, train_labels, 'train_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:16.923297Z",
     "start_time": "2019-03-14T07:37:16.817327Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(test_data, test_labels, 'test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:17.271828Z",
     "start_time": "2019-03-14T07:37:17.262977Z"
    }
   },
   "outputs": [],
   "source": [
    "def int2onehot(label):\n",
    "    \"\"\"conver labels into one-hot vector, !!YOU CAN READ THIS LATER, if you are interested\n",
    "    Args:\n",
    "        label: [batch_size]\n",
    "    Returns:\n",
    "        onehot: [batch_size, categories]\n",
    "    \"\"\"\n",
    "    dims = len(set(label))\n",
    "    imgs_size = len(label)\n",
    "    onehot = np.zeros((imgs_size, dims))\n",
    "    onehot[np.arange(imgs_size), label] = 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:17.923909Z",
     "start_time": "2019-03-14T07:37:17.919306Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert labels into one hot vector\n",
    "train_labels_onehot = int2onehot(train_labels)\n",
    "test_labels_onehot = int2onehot(test_labels)\n",
    "print(train_labels_onehot.shape)\n",
    "print(train_labels_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:18.381172Z",
     "start_time": "2019-03-14T07:37:18.375137Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, labels):\n",
    "    \"\"\"Compute accuracy, !!YOU CAN READ THIS LATER, if you are interested\n",
    "    Inputs: \n",
    "        predictions:[batch_size, categories] one-hot vector\n",
    "        labels: [batch_size, categories]\n",
    "    \"\"\"\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    labels = np.argmax(labels, axis=1)\n",
    "    all_imgs = len(labels)\n",
    "    predict_true = np.sum(predictions == labels)\n",
    "    return predict_true/all_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:19.210633Z",
     "start_time": "2019-03-14T07:37:19.199565Z"
    }
   },
   "outputs": [],
   "source": [
    "# Please read this function carefully, related to implementation of GD, SGD, and mini-batch\n",
    "def generate_batch(train_data, train_labels, batch_size):\n",
    "    \"\"\"Generate batch\n",
    "    when batch_size=len(train_data), it's GD\n",
    "    when batch_size=1, it's SGD\n",
    "    when batch_size>1 & batch_size<len(train_data), it's mini-batch, usually, batch_size=2,4,8,16...\n",
    "    \"\"\"\n",
    "    iterations = math.ceil(len(train_data)/batch_size)\n",
    "    for i in range(iterations):\n",
    "        index_from = i*batch_size\n",
    "        index_end = (i+1)*batch_size\n",
    "        yield (train_data[index_from:index_end], train_labels[index_from:index_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:37:19.783318Z",
     "start_time": "2019-03-14T07:37:19.780316Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_curve(ys, title):\n",
    "    \"\"\"plot curlve for Loss and Accuacy, !!YOU CAN READ THIS LATER, if you are interested\n",
    "    Args:\n",
    "        ys: loss or acc list\n",
    "        title: Loss or Accuracy\n",
    "    \"\"\"\n",
    "    x = np.array(range(len(ys)))\n",
    "    y = np.array(ys)\n",
    "    plt.plot(x, y, c='b')\n",
    "    plt.axis()\n",
    "    plt.title('{} Curve:'.format(title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('{} Value'.format(title))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Training model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:39:54.877348Z",
     "start_time": "2019-03-14T07:39:54.872317Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:39:55.161072Z",
     "start_time": "2019-03-14T07:39:55.155180Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 400 # training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:46:59.379268Z",
     "start_time": "2019-03-14T07:46:59.376845Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = len(train_data) # GD\n",
    "# batch_size = 1               # SGD\n",
    "# batch_size = 8               # mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:46:59.771487Z",
     "start_time": "2019-03-14T07:46:59.698915Z"
    }
   },
   "outputs": [],
   "source": [
    "model = FeedForward_Neural_Network(learning_rate) # declare a simple feedforward neural model\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for index, (xs, ys) in enumerate(generate_batch(train_data, train_labels_onehot, batch_size)):\n",
    "        predictions = model.forward(xs) # forward phase\n",
    "        loss += 1/2 * np.mean(np.sum(np.square(ys-predictions), axis=1)) # Mean square error\n",
    "        model.backward(xs, ys, predictions) # backward phase\n",
    "        \n",
    "    losses.append(loss)\n",
    "    \n",
    "    # train dataset acc computation\n",
    "    predictions = model.forward(train_data)\n",
    "    # compute acc on train dataset\n",
    "    accuracy = get_accuracy(predictions, train_labels_onehot)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print('Epoch: {}, has {} iterations'.format(i, index+1))\n",
    "        print('\\tLoss: {:.4f}, \\tAccuracy: {:.4f}'.format(loss, accuracy))\n",
    "        \n",
    "test_predictions = model.forward(test_data)\n",
    "# compute acc on test dataset\n",
    "test_accuracy = get_accuracy(test_predictions, test_labels_onehot)\n",
    "print('Test Accuracy: {:.4f}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### !!! Homework 1.   Describe the training procedure, based on codes above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your ans: (write down on this cell)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:47:03.503608Z",
     "start_time": "2019-03-14T07:47:03.404392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Draw losses curve using losses \n",
    "show_curve(losses, 'Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T07:46:06.748314Z",
     "start_time": "2019-03-14T07:46:06.646635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Draw Accuracy curve using accuracies\n",
    "show_curve(accuracies, 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T03:31:27.340903Z",
     "start_time": "2019-03-14T03:31:27.336567Z"
    }
   },
   "source": [
    "##### !!! Howework 2 \n",
    "set learning rate = 0.01 to train the model and show two curve below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### !!! Howework 3\n",
    "Use SGD and mini-batch to train model and show four curve below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
